import React, {useState, useRef, useEffect} from 'react';
import {useNavigate} from 'react-router-dom';
import {Mic, Play, Pause} from 'lucide-react';
import {FFmpeg} from '@ffmpeg/ffmpeg';
import WaveSurfer from 'wavesurfer.js';
import MicrophonePlugin from 'wavesurfer.js/dist/plugin/wavesurfer.microphone';
import useVoiceConvert from '../hooks/useVoicepackConvert';
import {ScaleLoader} from 'react-spinners';
import axiosInstance from '../utils/axiosInstance';
import GradientButton from "../components/common/GradientButton";


function VoiceCreate() {
  const [isRecording, setIsRecording] = useState(false);
  const [voicePackName, setVoicePackName] = useState('');
  const [timer, setTimer] = useState(0);
  const [audioBlob, setAudioBlob] = useState(null);
  const [isFFmpegLoaded, setIsFFmpegLoaded] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [duration, setDuration] = useState('00:00');
  const [currentTime, setCurrentTime] = useState(0);
  const {convertVoice, loading} = useVoiceConvert();
  const [isPolling, setIsPolling] = useState(false);
  const navigate = useNavigate();

  const ffmpegRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const timerRef = useRef(null);

  const waveformRef = useRef(null);
  const wavesurferRef = useRef(null);
  const audioStreamRef = useRef(null);


  useEffect(() => {
    const loadFFmpeg = async () => {
      const ffmpeg = new FFmpeg();
      await ffmpeg.load();
      ffmpegRef.current = ffmpeg;
      setIsFFmpegLoaded(true);
    };
    loadFFmpeg();
  }, []);

  useEffect(() => {
    if (!waveformRef.current) return;

    wavesurferRef.current = WaveSurfer.create({
      container: waveformRef.current,
      waveColor: '#6366F1',
      progressColor: '#6366F1',
      cursorColor: '#6366F1',
      barWidth: 3,
      height: 60,
      responsive: true,
      plugins: [MicrophonePlugin.create()],
    });

    wavesurferRef.current.on('finish', () => {
      setIsPlaying(false);
      setCurrentTime(wavesurferRef.current.getDuration());
    });

    return () => {
      wavesurferRef.current?.destroy();
    };
  }, []);

  useEffect(() => {
    if (!wavesurferRef.current || !audioBlob) return;

    const ws = wavesurferRef.current;
    const updateTime = () => setCurrentTime(ws.getCurrentTime());

    ws.on('audioprocess', updateTime);
    return () => {
      ws.un('audioprocess', updateTime);
    };
  }, [audioBlob]);

  const handleStartRecording = async () => {
    if (!isFFmpegLoaded) return alert('FFmpeg ë¡œë”© ì¤‘ì…ë‹ˆë‹¤.');

    const stream = await navigator.mediaDevices.getUserMedia({audio: true});
    audioStreamRef.current = stream;
    setAudioBlob(null);
    setTimer(0);
    audioChunksRef.current = [];

    wavesurferRef.current.microphone.start();

    mediaRecorderRef.current = new MediaRecorder(stream, {mimeType: 'audio/webm'});
    mediaRecorderRef.current.ondataavailable = (e) => {
      audioChunksRef.current.push(e.data);
    };
    mediaRecorderRef.current.onstop = async () => {
      clearInterval(timerRef.current);
      audioStreamRef.current?.getTracks().forEach((track) => track.stop());
      wavesurferRef.current.microphone.stop();

      const webmBlob = new Blob(audioChunksRef.current, {type: 'audio/webm'});

      try {
        const ffmpeg = ffmpegRef.current;
        const arrayBuffer = await webmBlob.arrayBuffer();

        await ffmpeg.writeFile('input.webm', new Uint8Array(arrayBuffer));
        await ffmpeg.exec(['-i', 'input.webm', 'output.wav']);
        const outputData = await ffmpeg.readFile('output.wav');

        const wavBlob = new Blob([outputData.buffer], {type: 'audio/wav'});
        setAudioBlob(wavBlob);


        const audioUrl = URL.createObjectURL(wavBlob);
        wavesurferRef.current.load(audioUrl);

        const tempAudio = new Audio(audioUrl);
        tempAudio.onloadedmetadata = () => {
          const dur = tempAudio.duration;
          setDuration(!isNaN(dur) ? formatTime(dur) : '00:00');
          setCurrentTime(0);
        };
      } catch (err) {
        console.error('WAV ë³€í™˜ ì˜¤ë¥˜:', err);
      }
    };

    mediaRecorderRef.current.start();
    setIsRecording(true);
    timerRef.current = setInterval(() => setTimer((prev) => prev + 1), 1000);
  };

  const handleStopRecording = () => {
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
  };

  const togglePlay = () => {
    if (!wavesurferRef.current) return;
    wavesurferRef.current.playPause();
    setIsPlaying((prev) => !prev);
  };

  const pollStatus = async (id, interval = 2000, maxAttempts = 20) => {
    let attempts = 0;

    return new Promise((resolve, reject) => {
      const checkStatus = async () => {
        try {
          const { data } = await axiosInstance.get(`/voicepack/convert/status/${id}`);
          console.log(data)
          if (data.status === 'COMPLETED') {
            resolve(data);
          } else if (attempts >= maxAttempts) {
            reject(new Error('í´ë§ ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼'));
          } else {
            attempts++;
            setTimeout(checkStatus, interval);
          }
        } catch (err) {
          reject(err);
        }
      };

      checkStatus();
    });
  };

  const handleCreateVoicePack = async () => {
    if (!voicePackName.trim() || !audioBlob) {
      alert('ì´ë¦„ê³¼ ë…¹ìŒì´ í•„ìš”í•©ë‹ˆë‹¤.');
      return;
    }

    try {
      setIsPolling(true); // í´ë§ ì‹œì‘ ì‹œì 
      const res = await convertVoice(voicePackName, audioBlob, 7);

      if (res?.id) {
        const result = await pollStatus(res.id); // í´ë§ ì‹œì‘
        console.log('âœ… ìµœì¢… ìƒíƒœ:', result);
        alert('ë³´ì´ìŠ¤íŒ© ìƒì„± ì™„ë£Œ!');
        navigate('/voice-store');
      }
    } catch (error) {
      console.error('ë³´ì´ìŠ¤íŒ© ìƒì„± ì˜¤ë¥˜:', error);
      alert('ë³´ì´ìŠ¤íŒ© ìƒì„± ì‹¤íŒ¨');
    } finally {
      setIsPolling(false); // âœ… ë¬´ì¡°ê±´ êº¼ì§
    }
  };


  const formatTime = (time) => {
    if (typeof time !== 'number' || isNaN(time)) return '00:00';
    const mins = String(Math.floor(time / 60)).padStart(2, '0');
    const secs = String(Math.floor(time % 60)).padStart(2, '0');
    return `${mins}:${secs}`;
  };

  return (
    <>
      {(loading || isPolling) && (
        <div
          className="absolute inset-0 bg-violet-50 bg-opacity-40 backdrop-blur-sm flex items-center justify-center z-50">
          <ScaleLoader color="#615FFF" height={40} width={4} radius={2} margin={3}/>
        </div>
      )}
      <>
        <h1 className="text-xl font-bold text-gray-900 mb-6">ë³´ì´ìŠ¤íŒ© ìƒì„±</h1>

        <h1 className="text-l font-bold text-gray-900 mb-2">
          ë³´ì´ìŠ¤íŒ© ì´ë¦„ <span className="text-red-500">*</span>
        </h1>
        <input
          value={voicePackName}
          onChange={(e) => setVoicePackName(e.target.value)}
          className="w-full px-4 py-2 border-none rounded-md mb-6 bg-slate-50 focus:outline-none focus:ring-1 focus:ring-indigo-400"
          placeholder="ë³´ì´ìŠ¤íŒ© ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
        />
        <div className="flex flex-col mb-2">
          <h2 className="text-l font-bold text-gray-900">
            ë³´ì´ìŠ¤íŒ© ìƒ˜í”Œ ë…¹ìŒ <span className="text-red-500">*</span>
          </h2>

          <div className="flex items-center text-sm text-gray-600 mb-4">
            <p>ë…¹ìŒ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬, ë…¹ìŒ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ì•„ë˜ ë¬¸ì¥ì„ ë”°ë¼ ì½ì–´ì£¼ì„¸ìš”.</p>
            <div className="relative group ml-2">
              <div
                className="w-4 h-4 flex items-center justify-center rounded-full bg-indigo-400 text-white text-xs cursor-default">
                !
              </div>
              <div
                className="absolute z-10 w-80 p-3 bg-slate-50 backdrop-blur-sm text-sm text-gray-700 border border-indigo-200 rounded-md opacity-0 group-hover:opacity-100 transition-opacity duration-300 top-1/2 left-full -translate-y-1/2 ml-2 pointer-events-none">
                ğŸ™ï¸ <b>ì¡°ìš©í•œ í™˜ê²½</b>ì—ì„œ ë…¹ìŒí•´ ì£¼ì„¸ìš”.<br/><br/>
                ğŸ’¡ <b>ì´ì–´í°ì´ë‚˜ ì™¸ë¶€ ë§ˆì´í¬</b> ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.<br/><br/>
                ğŸ”‡ <b>TV, ìŒì•…, ëŒ€í™” ë“±</b> ì†ŒìŒì„ ì¤„ì—¬ ì£¼ì„¸ìš”.
              </div>
            </div>
          </div>
        </div>

        <div className="bg-slate-50 rounded-md p-6">
          <p className="text-lg font-medium text-gray-800 mb-4">
            â€œ ì•ˆë…•í•˜ì„¸ìš”. ì§€ê¸ˆ ì œ ëª©ì†Œë¦¬ë¥¼ ë…¹ìŒí•˜ê³  ìˆì–´ìš”. ë˜ë ·í•˜ê²Œ ë“¤ë¦¬ì‹œë‚˜ìš”? ê°ì‚¬í•©ë‹ˆë‹¤. â€
          </p>

          <div className="flex items-center space-x-4">
            <button
              onClick={isRecording ? handleStopRecording : handleStartRecording}
              className={`w-12 h-12 rounded-full flex items-center justify-center text-white text-lg transition-colors duration-300 ${
                isRecording ? 'bg-indigo-500 ' : 'bg-gray-300 hover:bg-indigo-300'
              }`}
              disabled={!isFFmpegLoaded}
            >
              <Mic/>
            </button>

            <button
              onClick={togglePlay}
              className="w-12 h-12 rounded-full bg-indigo-500 text-white text-xl flex items-center justify-center shadow-md hover:bg-indigo-300 transition disabled:bg-gray-300"
              disabled={!audioBlob}
            >
              {isPlaying ? <Pause/> : <Play/>}
            </button>

            <div ref={waveformRef} className="flex-1 h-[60px]"/>

            <span className="text-sm w-24 text-right text-indigo-500">
              {audioBlob ? `${formatTime(currentTime)} / ${duration}` : formatTime(timer)}
            </span>
          </div>
        </div>
        <div className="mt-6 flex justify-end">
          <GradientButton
            className="px-6 py-3 disabled:opacity-50 disabled:cursor-not-allowed"
            onClick={handleCreateVoicePack}
            disabled={loading || !voicePackName.trim() || !audioBlob}
          >
            ìƒì„±í•˜ê¸°
          </GradientButton>
        </div>
      </>
    </>
  );
}

export default VoiceCreate;
